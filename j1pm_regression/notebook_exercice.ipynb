{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f7ce3e1",
   "metadata": {},
   "source": [
    "# Lab J1 — Après-midi : Régression Linéaire\n",
    "**Formation IA, Deep Learning & Machine Learning** — Julien Rolland\n",
    "**Public :** M2 Développement Fullstack\n",
    "\n",
    "---\n",
    "\n",
    "## Objectifs\n",
    "\n",
    "- Charger et explorer un dataset réel avec Pandas\n",
    "- Implémenter la solution analytique des moindres carrés en NumPy\n",
    "- Implémenter la descente de gradient from scratch\n",
    "- Comparer les trois approches (analytique, GD, sklearn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5e0ca9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T10:25:29.036324Z",
     "iopub.status.busy": "2026-03-01T10:25:29.036185Z",
     "iopub.status.idle": "2026-03-01T10:25:30.140507Z",
     "shell.execute_reply": "2026-03-01T10:25:30.140003Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "print('NumPy  :', np.__version__)\n",
    "print('Pandas :', pd.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd93848",
   "metadata": {},
   "source": [
    "---\n",
    "## Partie 1 — Dataset\n",
    "\n",
    "### 1.1 Chargement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f177c585",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T10:25:30.142130Z",
     "iopub.status.busy": "2026-03-01T10:25:30.141918Z",
     "iopub.status.idle": "2026-03-01T10:25:30.153813Z",
     "shell.execute_reply": "2026-03-01T10:25:30.153310Z"
    }
   },
   "outputs": [],
   "source": [
    "data = load_diabetes()\n",
    "\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "print('Shape :', df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fqgyx15018a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T10:25:30.155117Z",
     "iopub.status.busy": "2026-03-01T10:25:30.154989Z",
     "iopub.status.idle": "2026-03-01T10:25:30.157562Z",
     "shell.execute_reply": "2026-03-01T10:25:30.157091Z"
    }
   },
   "outputs": [],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50c1ba3",
   "metadata": {},
   "source": [
    "### 1.2 Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a0faa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T10:25:30.158970Z",
     "iopub.status.busy": "2026-03-01T10:25:30.158831Z",
     "iopub.status.idle": "2026-03-01T10:25:30.178733Z",
     "shell.execute_reply": "2026-03-01T10:25:30.178283Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe().round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a4b83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T10:25:30.179937Z",
     "iopub.status.busy": "2026-03-01T10:25:30.179829Z",
     "iopub.status.idle": "2026-03-01T10:25:30.182422Z",
     "shell.execute_reply": "2026-03-01T10:25:30.181963Z"
    }
   },
   "outputs": [],
   "source": [
    "print('NaN :', df.isna().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1de570a",
   "metadata": {},
   "source": [
    "### 1.3 Visualisation — BMI vs target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b27a29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T10:25:30.183415Z",
     "iopub.status.busy": "2026-03-01T10:25:30.183326Z",
     "iopub.status.idle": "2026-03-01T10:25:30.317018Z",
     "shell.execute_reply": "2026-03-01T10:25:30.316432Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.scatter(df['bmi'], df['target'], alpha=0.4, s=15)\n",
    "ax.set_xlabel('BMI (normalisé)')\n",
    "ax.set_ylabel('Progression de la maladie')\n",
    "ax.set_title('BMI vs Target')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7f0208",
   "metadata": {},
   "source": [
    "### 1.4 Corrélations features / cible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760114b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T10:25:30.318345Z",
     "iopub.status.busy": "2026-03-01T10:25:30.318238Z",
     "iopub.status.idle": "2026-03-01T10:25:30.414738Z",
     "shell.execute_reply": "2026-03-01T10:25:30.414373Z"
    }
   },
   "outputs": [],
   "source": [
    "corr = df.drop(columns='target').corrwith(df['target']).sort_values()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "colors = ['#d62728' if v < 0 else '#1f77b4' for v in corr]\n",
    "ax.barh(corr.index, corr.values, color=colors)\n",
    "ax.axvline(0, color='black', linewidth=0.8)\n",
    "ax.set_xlabel('Corrélation de Pearson avec target')\n",
    "ax.set_title('Corrélation features / cible')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0920c4bd",
   "metadata": {},
   "source": [
    "---\n",
    "## Partie 2 — Préparation des données\n",
    "\n",
    "### 2.1 Train / test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2e6503",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T10:25:30.416273Z",
     "iopub.status.busy": "2026-03-01T10:25:30.416158Z",
     "iopub.status.idle": "2026-03-01T10:25:30.419960Z",
     "shell.execute_reply": "2026-03-01T10:25:30.419536Z"
    }
   },
   "outputs": [],
   "source": [
    "X_raw = data.data          # (442, 10)\n",
    "y_raw = data.target        # (442,)\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X_raw, y_raw, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print('Train :', X_train_raw.shape, y_train.shape)\n",
    "print('Test  :', X_test_raw.shape,  y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1a0bfc",
   "metadata": {},
   "source": [
    "### 2.2 Ajout du biais\n",
    "\n",
    "Pour absorber le terme constant $b$ dans le vecteur de poids $\\mathbf{w}$, on augmente $X$ d'une colonne de 1 :\n",
    "\n",
    "$$\\tilde{X} = [\\mathbf{1} \\mid X], \\quad \\tilde{\\mathbf{w}} = [b, w_1, \\dots, w_d]^\\top$$\n",
    "\n",
    "$$\\hat{y} = \\tilde{X}\\, \\tilde{\\mathbf{w}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb328bcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T10:25:30.421339Z",
     "iopub.status.busy": "2026-03-01T10:25:30.421182Z",
     "iopub.status.idle": "2026-03-01T10:25:30.424301Z",
     "shell.execute_reply": "2026-03-01T10:25:30.423876Z"
    }
   },
   "outputs": [],
   "source": "def add_bias(X: np.ndarray) -> np.ndarray:\n    \"\"\"Prepend a column of ones to X.  Shape: (N, d) -> (N, d+1).\"\"\"\n    raise NotImplementedError"
  },
  {
   "cell_type": "markdown",
   "id": "02412d2d",
   "metadata": {},
   "source": [
    "### 2.3 Normalisation\n",
    "\n",
    "La descente de gradient est sensible à l'échelle des features : si une feature varie de 0 à 1000 et une autre de 0 à 1, leurs gradients ont des magnitudes très différentes et le même $\\alpha$ est trop grand pour l'une, trop petit pour l'autre.\n",
    "\n",
    "On centre-réduit chaque feature avec les statistiques du **train set** uniquement — utiliser les stats du test set constituerait une fuite de données (*data leakage*) :\n",
    "\n",
    "$$\\tilde{x}_j = \\frac{x_j - \\mu_j}{\\sigma_j}$$\n",
    "\n",
    "La colonne de biais (tout à 1) est ajoutée **après** normalisation : elle n'a pas à être normalisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747cc6c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T10:25:30.425872Z",
     "iopub.status.busy": "2026-03-01T10:25:30.425703Z",
     "iopub.status.idle": "2026-03-01T10:25:30.428853Z",
     "shell.execute_reply": "2026-03-01T10:25:30.428427Z"
    }
   },
   "outputs": [],
   "source": [
    "X_mean = X_train_raw.mean(axis=0)\n",
    "X_std  = X_train_raw.std(axis=0)\n",
    "\n",
    "X_train_norm = add_bias((X_train_raw - X_mean) / X_std)\n",
    "X_test_norm  = add_bias((X_test_raw  - X_mean) / X_std)\n",
    "\n",
    "print('X_train_norm shape :', X_train_norm.shape)\n",
    "print('X_test_norm  shape :', X_test_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5kbaupqgg4",
   "metadata": {},
   "source": [
    "---\n",
    "## Définition du modèle\n",
    "\n",
    "Deux fonctions réutilisées dans toutes les parties.\n",
    "\n",
    "**Prédiction linéaire**\n",
    "\n",
    "$$\\hat{y} = X\\mathbf{w}$$\n",
    "\n",
    "**Erreur quadratique moyenne (MSE)**\n",
    "\n",
    "$$\\mathcal{L} = \\frac{1}{N}\\sum_{i=1}^{N}(y_i - \\hat{y}_i)^2 = \\frac{1}{N}\\|y - \\hat{y}\\|^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oen30w44tt",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T10:25:30.430610Z",
     "iopub.status.busy": "2026-03-01T10:25:30.430446Z",
     "iopub.status.idle": "2026-03-01T10:25:30.433401Z",
     "shell.execute_reply": "2026-03-01T10:25:30.432965Z"
    }
   },
   "outputs": [],
   "source": "def predict(X: np.ndarray, w: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Prédiction linéaire.\n\n    Parameters\n    ----------\n    X : ndarray of shape (N, d)\n        Matrice de features avec colonne de biais prepended.\n    w : ndarray of shape (d,)\n        Vecteur de poids (biais inclus).\n\n    Returns\n    -------\n    y_hat : ndarray of shape (N,)\n        Valeurs prédites.\n    \"\"\"\n    raise NotImplementedError\n\n\ndef mse(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n    \"\"\"\n    Erreur quadratique moyenne.\n\n    Parameters\n    ----------\n    y_true : ndarray of shape (N,)\n        Valeurs cibles réelles.\n    y_pred : ndarray of shape (N,)\n        Valeurs prédites.\n\n    Returns\n    -------\n    float\n        (1/N) * ||y_true - y_pred||²\n    \"\"\"\n    raise NotImplementedError"
  },
  {
   "cell_type": "markdown",
   "id": "b88a2c16",
   "metadata": {},
   "source": [
    "---\n",
    "## Partie 3 — Solution Analytique\n",
    "\n",
    "La solution des moindres carrés minimise $\\|y - Xw\\|^2$ :\n",
    "\n",
    "$$\\mathbf{w}^* = (X^\\top X)^{-1} X^\\top y$$\n",
    "\n",
    "En pratique on résout le système linéaire $(X^\\top X)\\,\\mathbf{w} = X^\\top y$ avec `np.linalg.solve` (plus stable que l'inversion explicite).\n",
    "\n",
    "### 3.1 Implémentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qp5n01y5ut",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T10:25:30.434616Z",
     "iopub.status.busy": "2026-03-01T10:25:30.434505Z",
     "iopub.status.idle": "2026-03-01T10:25:30.436713Z",
     "shell.execute_reply": "2026-03-01T10:25:30.436269Z"
    }
   },
   "outputs": [],
   "source": "def analytical_solution(X: np.ndarray, y: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Régression linéaire par résolution analytique (OLS).\n\n    Parameters\n    ----------\n    X : ndarray of shape (N, d)\n        Matrice de features avec colonne de biais prepended.\n    y : ndarray of shape (N,)\n        Valeurs cibles.\n\n    Returns\n    -------\n    w : ndarray of shape (d,)\n        Vecteur de poids optimal.\n    \"\"\"\n    raise NotImplementedError"
  },
  {
   "cell_type": "markdown",
   "id": "f47ae7b8",
   "metadata": {},
   "source": [
    "### 3.2 Entraînement et évaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50e09bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T10:25:30.437676Z",
     "iopub.status.busy": "2026-03-01T10:25:30.437586Z",
     "iopub.status.idle": "2026-03-01T10:25:30.440159Z",
     "shell.execute_reply": "2026-03-01T10:25:30.439853Z"
    }
   },
   "outputs": [],
   "source": [
    "w_ols = analytical_solution(X_train_norm, y_train)\n",
    "\n",
    "y_pred_train_ols = predict(X_train_norm, w_ols)\n",
    "y_pred_test_ols  = predict(X_test_norm,  w_ols)\n",
    "\n",
    "mse_train_ols = mse(y_train, y_pred_train_ols)\n",
    "mse_test_ols  = mse(y_test,  y_pred_test_ols)\n",
    "\n",
    "print(f'OLS — MSE train : {mse_train_ols:.2f}')\n",
    "print(f'OLS — MSE test  : {mse_test_ols:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1c6a4a",
   "metadata": {},
   "source": [
    "### 3.3 Prédictions vs réalité\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ebb087",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T10:25:30.441301Z",
     "iopub.status.busy": "2026-03-01T10:25:30.441211Z",
     "iopub.status.idle": "2026-03-01T10:25:30.539978Z",
     "shell.execute_reply": "2026-03-01T10:25:30.539434Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "lims = [y_test.min(), y_test.max()]\n",
    "ax.scatter(y_test, y_pred_test_ols, alpha=0.5, s=20)\n",
    "ax.plot(lims, lims, 'r--', linewidth=1, label='y = ŷ')\n",
    "ax.set_xlabel('Valeurs réelles')\n",
    "ax.set_ylabel('Prédictions OLS')\n",
    "ax.set_title('Solution analytique — test set')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-partie4-new",
   "metadata": {},
   "source": [
    "---\n",
    "## Partie 4 — Descente de Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f67c63",
   "metadata": {},
   "source": [
    "### 4.1 Implémentation\n",
    "\n",
    "La mise à jour du gradient pour MSE est :\n",
    "\n",
    "$$\\mathbf{w} \\leftarrow \\mathbf{w} - \\alpha \\cdot \\frac{2}{N} X^\\top (X\\mathbf{w} - y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac3a7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T10:25:30.541128Z",
     "iopub.status.busy": "2026-03-01T10:25:30.541012Z",
     "iopub.status.idle": "2026-03-01T10:25:30.543790Z",
     "shell.execute_reply": "2026-03-01T10:25:30.543393Z"
    }
   },
   "outputs": [],
   "source": "def gradient_descent(\n    X: np.ndarray,\n    y: np.ndarray,\n    lr: float = 0.1,\n    n_iters: int = 1000,\n) -> tuple:\n    \"\"\"\n    Gradient descent for linear regression.\n\n    Returns\n    -------\n    w       : final weight vector, shape (d,)\n    history : MSE at each iteration, shape (n_iters,)\n    \"\"\"\n    N, d = X.shape\n    w = np.zeros(d)\n    history = np.empty(n_iters)\n\n    for i in range(n_iters):\n        raise NotImplementedError\n\n    return w, history"
  },
  {
   "cell_type": "markdown",
   "id": "0dd635a1",
   "metadata": {},
   "source": [
    "### 4.2 Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cb4ddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T10:25:30.545003Z",
     "iopub.status.busy": "2026-03-01T10:25:30.544889Z",
     "iopub.status.idle": "2026-03-01T10:25:30.960615Z",
     "shell.execute_reply": "2026-03-01T10:25:30.959926Z"
    }
   },
   "outputs": [],
   "source": [
    "w_gd, history = gradient_descent(X_train_norm, y_train, lr=0.1, n_iters=1000)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "ax.plot(history)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Itération')\n",
    "ax.set_ylabel('MSE (log scale)')\n",
    "ax.set_title('Courbe d\\'apprentissage — Descente de gradient')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80a69dc",
   "metadata": {},
   "source": [
    "### 4.3 Évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103b6d1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T10:25:30.962131Z",
     "iopub.status.busy": "2026-03-01T10:25:30.961975Z",
     "iopub.status.idle": "2026-03-01T10:25:30.965116Z",
     "shell.execute_reply": "2026-03-01T10:25:30.964600Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_train_gd = predict(X_train_norm, w_gd)\n",
    "y_pred_test_gd  = predict(X_test_norm,  w_gd)\n",
    "\n",
    "mse_train_gd = mse(y_train, y_pred_train_gd)\n",
    "mse_test_gd  = mse(y_test,  y_pred_test_gd)\n",
    "\n",
    "print(f'GD — MSE train : {mse_train_gd:.2f}')\n",
    "print(f'GD — MSE test  : {mse_test_gd:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cc2b08",
   "metadata": {},
   "source": [
    "---\n",
    "## Partie 5 — Comparaison avec scikit-learn\n",
    "\n",
    "### 5.1 LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f1f686",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T10:25:30.966518Z",
     "iopub.status.busy": "2026-03-01T10:25:30.966397Z",
     "iopub.status.idle": "2026-03-01T10:25:30.971528Z",
     "shell.execute_reply": "2026-03-01T10:25:30.970942Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train_norm[:, 1:], y_train)\n",
    "\n",
    "y_pred_train_sk = model.predict(X_train_norm[:, 1:])\n",
    "y_pred_test_sk  = model.predict(X_test_norm[:, 1:])\n",
    "\n",
    "mse_train_sk = mse(y_train, y_pred_train_sk)\n",
    "mse_test_sk  = mse(y_test,  y_pred_test_sk)\n",
    "\n",
    "print(f'sklearn — MSE train : {mse_train_sk:.2f}')\n",
    "print(f'sklearn — MSE test  : {mse_test_sk:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f152a9",
   "metadata": {},
   "source": [
    "### 5.2 Tableau comparatif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11294d4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T10:25:30.973001Z",
     "iopub.status.busy": "2026-03-01T10:25:30.972775Z",
     "iopub.status.idle": "2026-03-01T10:25:30.978730Z",
     "shell.execute_reply": "2026-03-01T10:25:30.978332Z"
    }
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Méthode'   : ['Analytique (OLS)', 'Gradient Descent', 'sklearn'],\n",
    "    'MSE train' : [mse_train_ols, mse_train_gd, mse_train_sk],\n",
    "    'MSE test'  : [mse_test_ols,  mse_test_gd,  mse_test_sk],\n",
    "}).set_index('Méthode').round(2)\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fcc187",
   "metadata": {},
   "source": [
    "### 5.3 Comparaison des coefficients appris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036d3dec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T10:25:30.979810Z",
     "iopub.status.busy": "2026-03-01T10:25:30.979710Z",
     "iopub.status.idle": "2026-03-01T10:25:31.147619Z",
     "shell.execute_reply": "2026-03-01T10:25:31.147045Z"
    }
   },
   "outputs": [],
   "source": [
    "coef_ols = w_ols[1:]\n",
    "coef_gd  = w_gd[1:]\n",
    "coef_sk  = model.coef_\n",
    "\n",
    "feature_names = data.feature_names\n",
    "x_pos = np.arange(len(feature_names))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.bar(x_pos - width, coef_ols, width, label='Analytique (OLS)')\n",
    "ax.bar(x_pos,         coef_gd,  width, label='Gradient Descent', alpha=0.8)\n",
    "ax.bar(x_pos + width, coef_sk,  width, label='sklearn', alpha=0.8)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(feature_names, rotation=45, ha='right')\n",
    "ax.axhline(0, color='black', linewidth=0.8)\n",
    "ax.set_ylabel('Coefficient')\n",
    "ax.set_title('Coefficients appris — OLS vs GD vs sklearn')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c92c0f",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusion\n",
    "\n",
    "| Méthode | MSE train | MSE test | Remarque |\n",
    "|---|---|---|---|\n",
    "| Analytique (OLS) | 2868.55 | 2900.19 | Solution exacte, $O(d^3)$ |\n",
    "| Descente de gradient | 2869.33 | 2895.30 | Itératif, scalable |\n",
    "| sklearn | 2868.55 | 2900.19 | Référence |\n",
    "\n",
    "> Les trois méthodes convergent vers la même solution : la **descente de gradient est la clé de tout le deep learning**. En passant d'une fonction de perte convexe (MSE) à des réseaux profonds non-convexes, le même algorithme reste au cœur de l'optimisation — complété par la rétropropagation pour calculer les gradients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q7fbks9lzec",
   "metadata": {},
   "source": [
    "---\n",
    "## Pour aller plus loin — Régression non-linéaire par transformation de features\n",
    "\n",
    "La régression linéaire ne peut fitter qu'un hyperplan : $\\hat{y} = \\mathbf{w}^\\top \\mathbf{x}$.\n",
    "\n",
    "Si la relation entre $x$ et $y$ est non-linéaire, il suffit de créer un **nouveau dataset** en appliquant une transformation $\\varphi$ à chaque observation, puis de faire tourner **exactement le même algorithme** dessus.\n",
    "\n",
    "$$\\varphi(\\mathbf{x}) = [1,\\ x_1,\\ x_1^2,\\ \\dots,\\ x_1^d,\\ x_2,\\ x_2^2,\\ \\dots,\\ x_2^d,\\ \\ldots]$$\n",
    "\n",
    "Le modèle reste linéaire en les paramètres $\\mathbf{w}$, mais devient non-linéaire en l'entrée $\\mathbf{x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w0thba77so",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T10:25:31.148893Z",
     "iopub.status.busy": "2026-03-01T10:25:31.148734Z",
     "iopub.status.idle": "2026-03-01T10:25:31.152405Z",
     "shell.execute_reply": "2026-03-01T10:25:31.152066Z"
    }
   },
   "outputs": [],
   "source": [
    "def phi(X: np.ndarray, degree: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Expansion polynomiale par feature.\n",
    "\n",
    "    Pour chaque colonne de X, génère les puissances x, x², ..., x^degree.\n",
    "    Ajoute une colonne de biais en tête.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray of shape (N, d)\n",
    "        Matrice de features (sans biais).\n",
    "    degree : int\n",
    "        Degré maximal.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_phi : ndarray of shape (N, 1 + d * degree)\n",
    "        Features transformées avec biais.\n",
    "    \"\"\"\n",
    "    cols = [np.ones(len(X))]\n",
    "    for j in range(X.shape[1]):\n",
    "        for p in range(1, degree + 1):\n",
    "            cols.append(X[:, j] ** p)\n",
    "    return np.stack(cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1k9gje24i3q",
   "metadata": {},
   "source": [
    "### Exemple — expansion de degré 2 sur BMI et s5\n",
    "\n",
    "BMI et s5 sont les deux features les plus corrélées avec la cible (cf. 1.4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hcvogw4kfp8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T10:25:31.153758Z",
     "iopub.status.busy": "2026-03-01T10:25:31.153651Z",
     "iopub.status.idle": "2026-03-01T10:25:31.158077Z",
     "shell.execute_reply": "2026-03-01T10:25:31.157678Z"
    }
   },
   "outputs": [],
   "source": [
    "# BMI = col 3, s5 = col 9 dans X_train_norm (après biais)\n",
    "X_sel_train = X_train_norm[:, [3, 9]]\n",
    "X_sel_test  = X_test_norm[:, [3, 9]]\n",
    "\n",
    "degree = 2\n",
    "X_phi_train = phi(X_sel_train, degree)\n",
    "X_phi_test  = phi(X_sel_test,  degree)\n",
    "\n",
    "print(f'Shape avant φ : {X_sel_train.shape}  →  après φ : {X_phi_train.shape}')\n",
    "\n",
    "model_phi = LinearRegression(fit_intercept=False)\n",
    "model_phi.fit(X_phi_train, y_train)\n",
    "\n",
    "mse_train_phi = mse(y_train, model_phi.predict(X_phi_train))\n",
    "mse_test_phi  = mse(y_test,  model_phi.predict(X_phi_test))\n",
    "\n",
    "print(f'φ(BMI, s5, d={degree}) — MSE train : {mse_train_phi:.2f} | MSE test : {mse_test_phi:.2f}')\n",
    "print(f'Baseline linéaire (10 features)  — MSE test  : {mse_test_ols:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ahszoor58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-03-01T10:25:31.158994Z",
     "iopub.status.busy": "2026-03-01T10:25:31.158894Z",
     "iopub.status.idle": "2026-03-01T10:25:31.254371Z",
     "shell.execute_reply": "2026-03-01T10:25:31.253793Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "lims = [y_test.min(), y_test.max()]\n",
    "ax.scatter(y_test, model_phi.predict(X_phi_test), alpha=0.5, s=20)\n",
    "ax.plot(lims, lims, 'r--', linewidth=1, label='y = ŷ')\n",
    "ax.set_xlabel('Valeurs réelles')\n",
    "ax.set_ylabel('Prédictions φ')\n",
    "ax.set_title(f'φ(BMI, s5, d={degree}) — test set')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2th22s0qdq1",
   "metadata": {},
   "source": [
    "**À vous de jouer !** Pouvez-vous réduire le MSE test ?\n",
    "\n",
    "Quelques pistes :\n",
    "- Changer le degré du polynôme\n",
    "- Utiliser plusieurs features à la fois (pas seulement le BMI)\n",
    "- Combiner des features entre elles ($x_\\text{bmi} \\times x_\\text{bp}$, ...)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}